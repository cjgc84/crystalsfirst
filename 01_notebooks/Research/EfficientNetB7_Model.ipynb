{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB7_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report, precision_score, recall_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqiK_AGI086"
      },
      "source": [
        "#Mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6rPivHB2wEh"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount() #you can unmount your drive with this code\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4cgx7VzDH6z"
      },
      "source": [
        "# Project Folder path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al0wP2kSkS3V"
      },
      "source": [
        "project_dir = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/\"\n",
        "%cd {project_dir} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwewhyRqvQ_r"
      },
      "source": [
        "# Image Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "source": [
        "## image settings\n",
        "img_height = 960\n",
        "img_width = 1280\n",
        "\n",
        "##################################################################################################################################\n",
        "##### CODE TO BE REMOVED\n",
        "# ## labels to be adapted based on desired classification \n",
        "classes = ['crystal', 'no_crystal']\n",
        "# classes = ['amorphous_precipitate', 'clear', 'crystal', 'impurity', 'homogenous_precipitate', 'inhomogenous_precipitate', 'phase_seperation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qor7JU604tSf"
      },
      "source": [
        "# Train / Val Split  +  Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRT_BTAFoPDw"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "#############  TRAIN  ############################################################\n",
        "# Training ImagaDataGenerator with Augmentation transf.\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255, \n",
        "                                  validation_split=0.3,\n",
        "                                  rotation_range=45, \n",
        "                                  # width_shift_range=0.2,\n",
        "                                  # height_shift_range=0.2,\n",
        "                                  # shear_range=0.005,\n",
        "                                  # zoom_range=[0.9, 1.4],\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True,\n",
        "                                  brightness_range=(.8,1.2),\n",
        "                                  fill_mode='nearest'\n",
        "                                  )\n",
        "\n",
        "# Create a flow from the directory using same seed and 'training' subset.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                # project_dir + \"labels/multi_class\", \n",
        "                                project_dir + \"labels/binary\",\n",
        "                                subset='training',\n",
        "                                class_mode='categorical',\n",
        "                                shuffle=True, \n",
        "                                seed=42, \n",
        "                                target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                batch_size=BATCH_SIZE\n",
        "                                )\n",
        "\n",
        "\n",
        "#############  VALIDATION ########################################################\n",
        "# Validation ImageDataGenerator with rescaling.\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255, \n",
        "                                  validation_split=0.3\n",
        "                                  )\n",
        "\n",
        "# Create a flow from the directory for validation data - seed=42\n",
        "# Choose subset = 'validation'\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "                                  # project_dir + \"labels/multi_class\", \n",
        "                                  project_dir + \"labels/binary\",\n",
        "                                  subset='validation',\n",
        "                                  class_mode='categorical',\n",
        "                                  shuffle=True, \n",
        "                                  seed=42, \n",
        "                                  target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                  batch_size=BATCH_SIZE\n",
        "                                  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLQULyAvJC3X"
      },
      "source": [
        "# Get classes from folder names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHAxkHX5JD3k"
      },
      "source": [
        "class_names = train_generator.labels\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1oAT80Zy6mn"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uoVvxSLJW9m"
      },
      "source": [
        "## Visualize sample data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmEA9c0JYes"
      },
      "source": [
        "# plt.figure(figsize=(10, 10))\n",
        "# for images, labels in train_ds.take(1):\n",
        "#   for i in range(4):\n",
        "#     ax = plt.subplot(2, 2, i + 1)\n",
        "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#     plt.title(class_names[labels[i]])\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6BXtXFJdW0"
      },
      "source": [
        "# Shape of training input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-MfMoenJi8s"
      },
      "source": [
        "for image_batch, labels_batch in train_generator:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dr0at41KcAU"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "# TO BE DONE:  \n",
        "`Dataset.cache()` \n",
        "or\n",
        "`Dataset.prefetch()` \n",
        "(https://www.tensorflow.org/guide/data_performance#prefetching)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOjJSm7DKoZA"
      },
      "source": [
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmpeaN369d-n"
      },
      "source": [
        "## Defining the step size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeUeNhLy9Wek"
      },
      "source": [
        "steps_train = round(train_generator.n / BATCH_SIZE)\n",
        "steps_val = round(val_generator.n / BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1xjo3WeffQ"
      },
      "source": [
        "# Balancing Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOOeEaDKedHj"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(train_generator.classes),\n",
        "                                    y=train_generator.classes)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3OTxtcGhfaX"
      },
      "source": [
        "# class_weight has to be a dictionary format\n",
        "class_weight_dict = { i : class_weights[i] for i in range(0, len(class_weights))}\n",
        "class_weight_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ4RafP3i9YN"
      },
      "source": [
        "# getting number of classes\n",
        "num_classes = len(class_weights)\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fVmMF0wmqWl"
      },
      "source": [
        "# ## Plot sample images\n",
        "# x,y = train_generator.next()\n",
        "# for i in range(0,5):\n",
        "#     image = x[i]\n",
        "#     plt.imshow(image)\n",
        "#     plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AvIpQXNpLmP"
      },
      "source": [
        "# Setting up Efficient Net\n",
        "https://keras.io/api/applications/efficientnet/#efficientnetb7-function\n",
        "\n",
        "https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WprkhXS4o7Bd"
      },
      "source": [
        "input_t = tf.keras.Input(shape = (224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q_PAn66olsL"
      },
      "source": [
        "# load new instance of Efficient Net B7\n",
        "effnet_model = tf.keras.applications.EfficientNetB7(input_tensor = input_t,\n",
        "                                              include_top=False, # do not include ImageNet classifier at the top\n",
        "                                              weights='imagenet',\n",
        "                                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItbIUa_ipU9b"
      },
      "source": [
        "effnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3tFD-QsqxBa"
      },
      "source": [
        "# Transfer Learning\n",
        "Should try different \"opening layers\" strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1ithwBaU4YA"
      },
      "source": [
        "# Efficient Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLH4lqpVrPmK"
      },
      "source": [
        "# Setting all layer to not trainable except for last layer\n",
        "effnet_model.trainable = False\n",
        "for layer in effnet_model.layers:\n",
        "   if ((('block7d' in layer.name) or (\"top_\" in layer.name)) and ('bn' not in layer.name)):\n",
        "     layer.trainable = True    \n",
        "\n",
        "# effnet_model.trainable = True\n",
        "# for layer in effnet_model.layers:\n",
        "#    if ('bn' in layer.name):\n",
        "#      layer.trainable = False   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_IdUDbmsC_H"
      },
      "source": [
        "for layer in effnet_model.layers:\n",
        "    print(layer.name, '->', layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMDUKSNEs16I"
      },
      "source": [
        "last_conv_layer = effnet_model.get_layer('top_activation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mg_vwvJnQM"
      },
      "source": [
        "# Setting up New_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNwLCFExD4wy"
      },
      "source": [
        "\n",
        "conv_model = Model(inputs=effnet_model.input,\n",
        "                    outputs=last_conv_layer.output)\n",
        "\n",
        "new_model = Sequential()\n",
        "\n",
        "# new_model.add(resize_layer)\n",
        "\n",
        "# conv_model.add_loss(1.0)\n",
        "new_model.add(conv_model)\n",
        "\n",
        "new_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "new_model.add(tf.keras.layers.Dropout(0.4)) \n",
        "\n",
        "new_model.add(tf.keras.layers.Dense(2, activation='softmax')) \n",
        "# new_model.add(tf.keras.layers.Dense(7, activation='softmax')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkk6a0MtTXbu"
      },
      "source": [
        "# Optimizer\n",
        "best optimizer is ADAM, but others could be tested.   \n",
        "Learning rate to be adjusted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD_E6MS46Dxg"
      },
      "source": [
        "optimizer = Adam(lr=1e-4)\n",
        "optimizer.lr.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKFzz72Lqpg"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "Cross entropy loss function for binary classification\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjHlb2comd07"
      },
      "source": [
        "# ## Binary Crossentropy \n",
        "# new_model.compile(optimizer= optimizer,\n",
        "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "#               metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t5PywPCa7OF"
      },
      "source": [
        "# Categorical\n",
        "new_model.compile(optimizer= optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMJ4DnuJL55A"
      },
      "source": [
        "## Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoWU1F46UjZx"
      },
      "source": [
        "## Transfer learning moderl summary.... check if layers are open or not....\n",
        "conv_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YEXYSl2-QO9"
      },
      "source": [
        "## open orclose transfer leanong model layers\n",
        "# conv_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJxvjEdECs8m"
      },
      "source": [
        "## complete model layers\n",
        "for layer in new_model.layers:\n",
        "    print(layer.name, '->', layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLYH-BXL7Xe"
      },
      "source": [
        "## complete model summary\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYHcbvaL9H-"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y11T_EQaxLY0"
      },
      "source": [
        "# training initially\n",
        "epochs = 100\n",
        "history = new_model.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch=steps_train,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps = steps_val,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fWToCqYMErH"
      },
      "source": [
        "new_epochs = 20\n",
        "epochs += new_epochs\n",
        "\n",
        "# training including previous training\n",
        "history = new_model.fit(\n",
        "  train_generator,\n",
        "  initial_epoch=history.epoch[-1]+1,\n",
        "  epochs = epochs,\n",
        "  \n",
        "  steps_per_epoch=steps_train,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps = steps_val,\n",
        "  class_weight = class_weight_dict\n",
        "  \n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFKdQpXMJT4"
      },
      "source": [
        "## Visualize training results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWnopEChMMCn"
      },
      "source": [
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwto09piGhgD"
      },
      "source": [
        "# Save Model\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6utodzWGeuf"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "new_model.save('saved_model/EffNet_4') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vei3mjVXHi_1"
      },
      "source": [
        "# model directory\n",
        "# !ls saved_model\n",
        "\n",
        "# # Contains an assets folder, saved_model.pb, and variables folder.\n",
        "# !ls saved_model/EffNet_3/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axlXDgFMRCan"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZYVASiHfDQP"
      },
      "source": [
        "# Predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8pDTtSoTboo"
      },
      "source": [
        "folder_path = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/labels/test_small/\"\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
        "      img = keras.preprocessing.image.load_img(folder_path+filename,\n",
        "                                               target_size=(IMG_SIZE, IMG_SIZE))\n",
        "      img_array = keras.preprocessing.image.img_to_array(img)/255\n",
        "      img_array = tf.expand_dims(img_array, 0)\n",
        "      pred = new_model.predict(img_array)\n",
        "      predictions[filename] = (classes[np.argmax(pred)],\n",
        "                               (\"confidance of {:.2f}%\".format(100 * np.max(pred))))\n",
        "      continue\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOmJrUE0pAeu"
      },
      "source": [
        "collection = []\n",
        "for i in predictions.values():\n",
        "  collection.append(i[0])\n",
        "\n",
        "num_crystal = 0\n",
        "num_no_crystal = 0\n",
        "for i in collection:\n",
        "  if i == 'crystal':\n",
        "    num_crystal += 1 \n",
        "  if i == 'no_crystal':\n",
        "    num_no_crystal += 1 \n",
        "    \n",
        "print(\"Number of crystals:\", num_crystal, \"\\n\",\n",
        "      \"Number of NO crystals\", num_no_crystal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JMwS22-XAp4"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeD35VzAOtX-"
      },
      "source": [
        "import pandas as pd\n",
        "# create different df depending on binary / multi calss problem\n",
        "df_json = pd.read_json(project_dir+\"source/image_labels.json\", orient=\"columns\")\n",
        "#df_json = df_json.set_index(\"index\")\n",
        "df_json.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eXXGIESPYi8"
      },
      "source": [
        "df_pred = pd.DataFrame.from_dict(predictions, orient=\"index\").reset_index()                    \n",
        "df_pred.columns = [\"image\", \"predictions\",\"confidence\"]\n",
        "df_pred = df_pred.set_index(\"image\")\n",
        "df_pred.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emsL4t7jP7p3"
      },
      "source": [
        "cm_df = pd.concat([df_pred, df_json], axis=1, join='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAMngNGZ4i7P"
      },
      "source": [
        "cm_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFqpShf2XhWZ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(cm_df.loc[:,\"y_true\"], cm_df.loc[:,\"predictions\"], labels = ['crystal', 'no_crystal'])\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu5CjRRmUvNB"
      },
      "source": [
        "import seaborn as sn\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "labels = ['crystal', 'no_crystal']\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "sn.heatmap(cm, annot=True, xticklabels=True, yticklabels=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticklabels(labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwRU057FfADz"
      },
      "source": [
        "# Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCdnkjszfGvp"
      },
      "source": [
        "cr = classification_report(cm_df.loc[:,\"y_true\"], cm_df.loc[:,\"predictions\"], labels = ['crystal', 'no_crystal'], digits=2, zero_division='warn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVQ1TItpfKdW"
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L-JoLBFf-Vj"
      },
      "source": [
        "# Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_H-nlGcX45d"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9HMn20Y8AOR"
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "######################### only deleting the corresponding folder and not all other folder ###############\n",
        "!rm -rf logs/hparam_tuning_EffNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa5P6DOY8Cn-"
      },
      "source": [
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LykbBXpm8EwI"
      },
      "source": [
        "# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([200, 250, 300]))\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1, 0.2, 0.4]))\n",
        "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'nadam', 'sgd']))\n",
        "# HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['softmax', 'sigmoid']))\n",
        "# HP_LEARNINGRATE = hp.HParam('learningrate', hp.Discrete([0.001, 0.0001, 0.00001]))\n",
        "# HP_EPOCHS = hp.HParam('epochs', hp.Discrete([20, 50, 70]))\n",
        "# HP_BATCHS = hp.HParam('batches', hp.Discrete([5, 8, 10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wppKDt4Q8G06"
      },
      "source": [
        "# METRIC_ACCURACY = 'categorical_accuracy'\n",
        "\n",
        "# with tf.summary.create_file_writer('logs/hparam_tuning_EffNet').as_default():\n",
        "#   hp.hparams_config(\n",
        "#     hparams=[HP_DROPOUT, HP_OPTIMIZER, HP_ACTIVATION, HP_LEARNINGRATE, HP_EPOCHS, HP_BATCHS],\n",
        "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAmAO1-uCkgv"
      },
      "source": [
        "def train_test_model(hparams, logs):\n",
        "## ResNet #############################################################################\n",
        "#   conv_model = Model(inputs=effnet_model.input,\n",
        "#                    outputs=last_conv_layer.output)\n",
        "\n",
        "#   new_model = tf.keras.Sequential()\n",
        "#   new_model.add(conv_model)\n",
        "#   new_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "# # new_model.add(tf.keras.layers.Flatten()) # flatten has similar effect as GAP\n",
        "#   new_model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT])) #dropout after dense layer is usually recommended\n",
        "# # new_model.add(tf.keras.layers.Dense(2, activation=\"relu\")) \n",
        "#   new_model.add(tf.keras.layers.Dense(2, activation= hparams[HP_ACTIVATION])) \n",
        "  \n",
        "  \n",
        "#   new_model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
        "#                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "#                 metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "  \n",
        "\n",
        "#   new_model.fit(\n",
        "#   train_generator,\n",
        "#   steps_per_epoch=steps_train,\n",
        "#   validation_data=val_generator,\n",
        "#   validation_steps = steps_val,\n",
        "#   callbacks = [tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "#                                                  write_graph = True,\n",
        "#                                                  histogram_freq = 1,\n",
        "#                                                  profile_batch = '500,520')],\n",
        "#   class_weight = class_weight_dict,\n",
        "#   epochs = hparams[HP_EPOCHS]\n",
        "\n",
        "# )\n",
        "\n",
        "#   _, accuracy = new_model.evaluate(val_generator)\n",
        "#   return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SjWxr2sHWvc"
      },
      "source": [
        "# def run(run_dir, hparams):\n",
        "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
        "#     hp.hparams(hparams)  # record the values used in this trial\n",
        "#     accuracy = train_test_model(hparams, run_dir)\n",
        "#     tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfDqBektHgvY"
      },
      "source": [
        "# session_num = 0\n",
        "# for dropout_rate in HP_DROPOUT.domain.values:\n",
        "#   for activation in HP_ACTIVATION.domain.values:\n",
        "#     for optimizer in HP_OPTIMIZER.domain.values:\n",
        "#       for epochs in HP_EPOCHS.domain.values:\n",
        "          \n",
        "#           hparams = {\n",
        "#               HP_DROPOUT: dropout_rate,\n",
        "#               HP_ACTIVATION: activation,\n",
        "#               HP_OPTIMIZER: optimizer,\n",
        "#               HP_EPOCHS: epochs,\n",
        "              \n",
        "#           }\n",
        "\n",
        "#           ############ change the folder name here in run ####################\n",
        "#           run_name = \"run-%d\" % session_num\n",
        "#           print('--- Starting trial: %s' % run_name)\n",
        "#           print({h.name: hparams[h] for h in hparams})\n",
        "#           run('logs/hparam_tuning_EffNet/' + run_name, hparams)\n",
        "#           session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4IFSqH2Bj5P"
      },
      "source": [
        "# !pip install -U tensorboard_plugin_profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kPjr1jcBsBl"
      },
      "source": [
        "# !kill 1267 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7VOXX9BHjun"
      },
      "source": [
        "%tensorboard --logdir logs/hparam_tuning_EffNet/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}