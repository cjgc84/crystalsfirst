{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Nadam, SGD, RMSprop\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report, precision_score, recall_score\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from typeguard import typechecked\n",
        "from tensorflow_addons.utils.types import AcceptableDTypes, FloatTensorLike\n",
        "from typing import Optional\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqiK_AGI086"
      },
      "source": [
        "#Mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6rPivHB2wEh"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount() #you can unmount your drive with this code\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4cgx7VzDH6z"
      },
      "source": [
        "# Project Folder path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al0wP2kSkS3V"
      },
      "source": [
        "project_dir = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/\"\n",
        "%cd {project_dir} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwewhyRqvQ_r"
      },
      "source": [
        "# Image Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "source": [
        "## image settings\n",
        "img_height = 960\n",
        "img_width = 1280\n",
        "\n",
        "## labels to be adapted based on desired classification \n",
        "classes = ['crystal', 'no_crystal']\n",
        "# classes = ['amorphous_precipitate', 'clear', 'crystal', 'impurity', 'homogenous_precipitate', 'inhomogenous_precipitate', 'phase_seperation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qor7JU604tSf"
      },
      "source": [
        "# Train / Val   +  Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRT_BTAFoPDw"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "#############  TRAIN  ############################################################\n",
        "# Training ImagaDataGenerator with Augmentation transf.\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255, \n",
        "                                  validation_split=0.3,\n",
        "                                  rotation_range=45, \n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  # shear_range=0.005,\n",
        "                                  # zoom_range=[0.9, 1.4],\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True,\n",
        "                                  brightness_range=(.8,1.2),\n",
        "                                  fill_mode='nearest'\n",
        "                                  )\n",
        "\n",
        "# Create a flow from the directory using same seed and 'training' subset.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                project_dir + \"labels/binary_original\", \n",
        "                                subset='training',\n",
        "                                class_mode='categorical',\n",
        "                                # class_mode='binary',\n",
        "                                shuffle=True, \n",
        "                                seed=42, \n",
        "                                target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                batch_size=BATCH_SIZE\n",
        "                                )\n",
        "\n",
        "\n",
        "#############  VALIDATION ########################################################\n",
        "# Validation ImageDataGenerator with rescaling.\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255, \n",
        "                                  validation_split=0.3\n",
        "                                  )\n",
        "\n",
        "# Create a flow from the directory for validation data - seed=42\n",
        "# Choose subset = 'validation'\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "                                  project_dir + \"labels/binary_original\",\n",
        "                                  subset='validation',\n",
        "                                  class_mode='categorical',\n",
        "                                  # class_mode='binary',\n",
        "                                  shuffle=True, \n",
        "                                  seed=42, \n",
        "                                  target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                  batch_size=BATCH_SIZE\n",
        "                                  )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z_nSmaI5elc"
      },
      "source": [
        "# ## Plot sample images\n",
        "# x,y = train_generator.next()\n",
        "# print(x.shape, y.shape)\n",
        "# for i in range(0,5):\n",
        "#     image = x[i]\n",
        "#     plt.title(y[i])\n",
        "#     plt.imshow(image)\n",
        "#     plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLQULyAvJC3X"
      },
      "source": [
        "# Get classes from folder names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHAxkHX5JD3k"
      },
      "source": [
        "# class_names = train_generator.labels\n",
        "# print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTqG1jv2GIHO"
      },
      "source": [
        "# len(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1oAT80Zy6mn"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6BXtXFJdW0"
      },
      "source": [
        "# Shape of training input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-MfMoenJi8s"
      },
      "source": [
        "for image_batch, labels_batch in train_generator:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dr0at41KcAU"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "# TO BE DONE:  \n",
        "`Dataset.cache()` \n",
        "or\n",
        "`Dataset.prefetch()` \n",
        "(https://www.tensorflow.org/guide/data_performance#prefetching)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOjJSm7DKoZA"
      },
      "source": [
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmpeaN369d-n"
      },
      "source": [
        "## Defining the step size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeUeNhLy9Wek"
      },
      "source": [
        "steps_train = round(train_generator.n / BATCH_SIZE)\n",
        "steps_val = round(val_generator.n / BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1xjo3WeffQ"
      },
      "source": [
        "# Balancing Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOOeEaDKedHj"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(train_generator.classes),\n",
        "                                    y=train_generator.classes)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3OTxtcGhfaX"
      },
      "source": [
        "# class_weight has to be a dictionary format\n",
        "class_weight_dict = { i : class_weights[i] for i in range(0, len(class_weights))}\n",
        "class_weight_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ4RafP3i9YN"
      },
      "source": [
        "# # getting number of classes\n",
        "# num_classes = len(class_weights)\n",
        "# num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fVmMF0wmqWl"
      },
      "source": [
        "# ## Plot sample images\n",
        "# x,y = train_generator.next()\n",
        "# for i in range(0,5):\n",
        "#     image = x[i]\n",
        "#     plt.imshow(image)\n",
        "#     plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7mkhp5RJjcy"
      },
      "source": [
        "# Setting up VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WprkhXS4o7Bd"
      },
      "source": [
        "input_t = tf.keras.Input(shape = (224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKj5HxqFCDoU"
      },
      "source": [
        "# load a new instance of the ResNet model.\n",
        "VGG19_model = tf.keras.applications.VGG19(input_tensor = input_t,\n",
        "                                              include_top=False, # do not include ImageNet classifier at the top\n",
        "                                              weights='imagenet',\n",
        "                                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEKn7vW7CF11"
      },
      "source": [
        "VGG19_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3tFD-QsqxBa"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiuxIDcGIqxO"
      },
      "source": [
        "# VGG19_model.trainable = False\n",
        "# for layer in VGG19_model.layers:\n",
        "#    if 'block5_' in layer.name:\n",
        "#      layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjPVfAeSd21e"
      },
      "source": [
        "Fine Tuning / Opening up more layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ABzGwzkd1mr"
      },
      "source": [
        "# # Fine-tune from this layer onwards\n",
        "# VGG19_model.trainable = True\n",
        "# fine_tune_at = 16 # 16 = block_4_pool and all block_5 open\n",
        "\n",
        "# # Freeze all the layers before the `fine_tune_at` layer\n",
        "# for layer in VGG19_model.layers[:fine_tune_at]:\n",
        "#   layer.trainable =  False\n",
        "\n",
        "\n",
        "\"\"\" model behaves the best when all VGG layers are closed\"\"\"\n",
        "# mark loaded layers as not trainable\n",
        "for layer in VGG19_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXM0LLs4Iq1X"
      },
      "source": [
        "for layer in VGG19_model.layers:\n",
        "    print(layer.name, '->', layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnbjIR9DhPw"
      },
      "source": [
        "# points to last layer\n",
        "last_conv_layer = VGG19_model.get_layer('block5_pool')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mg_vwvJnQM"
      },
      "source": [
        "# Setting up New_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNwLCFExD4wy"
      },
      "source": [
        "## Convolutional  model\n",
        "conv_model = Model(inputs=VGG19_model.input,\n",
        "                   outputs=last_conv_layer.output)\n",
        "## Start a new Keras Sequential model\n",
        "new_model = Sequential()\n",
        "new_model.add(conv_model)\n",
        "## Add more layers\n",
        "new_model.add(tf.keras.layers.Flatten())\n",
        "new_model.add(tf.keras.layers.Dense(512, activation='relu')) \n",
        "new_model.add(tf.keras.layers.Dense(2, activation='softmax')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0FQwkhdQAlP"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkk6a0MtTXbu"
      },
      "source": [
        "# Optimizer\n",
        "best optimizer is ADAM, but others could be tested.   \n",
        "Learning rate to be adjusted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD_E6MS46Dxg"
      },
      "source": [
        "optimizer = Adam(lr=1e-3)\n",
        "optimizer.lr.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKFzz72Lqpg"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "Cross entropy loss function for binary classification\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjHlb2comd07"
      },
      "source": [
        "# ## Binary Crossentropy \n",
        "# new_model.compile(optimizer= optimizer,\n",
        "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "#               metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t5PywPCa7OF"
      },
      "source": [
        "# #  Sparse Categorical\n",
        "# new_model.compile(optimizer= optimizer,\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "#               metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTu2g2j_Lewb"
      },
      "source": [
        "# Categorical\n",
        "new_model.compile(optimizer= optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMJ4DnuJL55A"
      },
      "source": [
        "## Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoWU1F46UjZx"
      },
      "source": [
        "## Transfer learning moderl summary.... check if layers are open or not....\n",
        "# conv_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YEXYSl2-QO9"
      },
      "source": [
        "## open orclose transfer leanong model layers\n",
        "# conv_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJxvjEdECs8m"
      },
      "source": [
        "## complete model layers\n",
        "for layer in new_model.layers:\n",
        "    print(layer.name, '->', layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLYH-BXL7Xe"
      },
      "source": [
        "## complete model summary\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYHcbvaL9H-"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fWToCqYMErH"
      },
      "source": [
        "%%time\n",
        "epochs = 50\n",
        "history = new_model.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch=steps_train,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps = steps_val,\n",
        "  # callbacks = [tboard_callback],\n",
        "  class_weight = class_weight_dict,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFKdQpXMJT4"
      },
      "source": [
        "## Visualize training results  \n",
        "Create plots of loss and accuracy on the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWnopEChMMCn"
      },
      "source": [
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBeEoUbcNGxG"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kitmgjIrNGH1"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "new_model.save('saved_model/VGG19_batch_16_epoch_50') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCLTP_3TNQGn"
      },
      "source": [
        "# # model directory\n",
        "# !ls saved_model\n",
        "\n",
        "# # Contains an assets folder, saved_model.pb, and variables folder.\n",
        "# !ls saved_model/VGG19_2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhPkUr77MA3T"
      },
      "source": [
        "# Test / Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb1dWmvC2qhh"
      },
      "source": [
        "new_model = tf.keras.models.load_model('saved_model/VGG19_batch_16_epoch_50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC40sRITBSsQ"
      },
      "source": [
        "folder_path = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/labels/test/\"\n",
        "\n",
        "\n",
        "#####  TEST ON LARGE SET #####\n",
        "folder_path = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/labels/test_on_wellimages_17/\"\n",
        "##############################\n",
        "\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if (filename.endswith(\".jpg\") or filename.endswith(\".JPG\")):\n",
        "      img = keras.preprocessing.image.load_img(folder_path+filename,\n",
        "                                               target_size=(IMG_SIZE, IMG_SIZE))\n",
        "      img_array = keras.preprocessing.image.img_to_array(img)/255\n",
        "      img_array = tf.expand_dims(img_array, 0)\n",
        "      pred = new_model.predict(img_array)\n",
        "      predictions[filename] = (classes[np.argmax(pred)],\n",
        "                               (\"confidance of {:.2f}%\".format(100 * np.max(pred))))\n",
        "      continue\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g9eIaj66Lch"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNHIxcZOqnr"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8nTwynOOtXo"
      },
      "source": [
        "import pandas as pd\n",
        "df_json = pd.read_json(project_dir+\"source/image_labels.json\", orient=\"columns\")\n",
        "# df_json.columns=[\"image\",\"original_labels\"]\n",
        "df_json.columns=[\"original_labels\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps_pThRt5kLn"
      },
      "source": [
        "# df_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXDfxABfOvpn"
      },
      "source": [
        "df_pred = pd.DataFrame.from_dict(predictions)                     \n",
        "df_pred = df_pred.T\n",
        "df_pred = df_pred.drop(1, axis=1)\n",
        "# df_pred = df_pred.reset_index()\n",
        "# df_pred.columns = [\"image\", \"predictions\"]\n",
        "df_pred.columns = [\"predictions\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXkX4NUMO0Ii"
      },
      "source": [
        "cm_df = pd.concat([df_pred, df_json], axis=1, join='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujeB9jbE5p01"
      },
      "source": [
        "cm_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKRFCy6GO2W0"
      },
      "source": [
        "cm = confusion_matrix(cm_df.loc[:,\"original_labels\"], cm_df.loc[:,\"predictions\"])\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0CW75auO3pn"
      },
      "source": [
        "import seaborn as sn\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "labels = ['crystal', 'no_crystal']\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "sn.heatmap(cm, annot=True, xticklabels=True, yticklabels=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticklabels(labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmNf5oLYeiKY"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfS4Fxe3ek6c"
      },
      "source": [
        "cr = classification_report(cm_df.loc[:,\"original_labels\"], cm_df.loc[:,\"predictions\"], labels = ['crystal', 'no_crystal'], digits=2, zero_division='warn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQPzok_Een2B"
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2aRQgfi6E2Q"
      },
      "source": [
        "## ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO2A5q-N6EOH"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eKiuUDW8jAi"
      },
      "source": [
        "cm_df.replace(to_replace=\"no_crystal\", value=1, inplace=True)\n",
        "cm_df.replace(to_replace=\"crystal\", value=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzM9i6egDDVE"
      },
      "source": [
        "def plot_roc(y_test, proba_preds):\n",
        "\n",
        "    # create linear line\n",
        "    base_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "    base_auc = roc_auc_score(y_test, base_probs)\n",
        "    lr_auc = roc_auc_score(y_test, proba_preds)\n",
        "\n",
        "    # summarize scores\n",
        "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "    # calculate roc curves\n",
        "    ns_fpr, ns_tpr, _ = roc_curve(y_test, base_probs)\n",
        "    lr_fpr, lr_tpr, _ = roc_curve(y_test, proba_preds)\n",
        "\n",
        "    # plot the roc curve for the model\n",
        "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Base')\n",
        "    plt.plot(lr_fpr, lr_tpr, marker='.', label='VGG19')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCTo8Xv-DDd_"
      },
      "source": [
        "plot_roc(cm_df.loc[:,\"original_labels\"], \n",
        "         cm_df.loc[:,\"predictions\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLrQ5dSVDDak"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBn3uHNSDDYM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A7vGVuCDDST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG3BI7dA6EhF"
      },
      "source": [
        "fpr, tpr, thresholds "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0VNVuuoRqYj"
      },
      "source": [
        "# Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWCLJnwCRlg2"
      },
      "source": [
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1UjUJOcRlpM"
      },
      "source": [
        "# # Clear any logs from previous runs\n",
        "# ######################################################## only deleting the corresponding folder and not all other folder ###############\n",
        "# !rm -rf ./logs/hparam_tuning_VGG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLBfmeBQ73D"
      },
      "source": [
        "# from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcjd15mcQUwA"
      },
      "source": [
        "# HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.3]))\n",
        "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['Adam', 'RMSprop']))\n",
        "# HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['softmax'])) \n",
        "# HP_LEARNINGRATE = hp.HParam('learningrate', hp.Discrete([0.001, 0.0001, 0.00001]))\n",
        "# HP_EPOCHS = hp.HParam('epochs', hp.Discrete([10, 20]))\n",
        "# HP_BATCHS = hp.HParam('epochs', hp.Discrete([16, 32]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj3YjQHAQajQ"
      },
      "source": [
        "# METRIC_ACCURACY = 'categorical_accuracy'\n",
        "\n",
        "# with tf.summary.create_file_writer('./logs/hparam_tuning_VGG').as_default():\n",
        "#   hp.hparams_config(\n",
        "#     hparams=[HP_DROPOUT, HP_OPTIMIZER, HP_ACTIVATION, HP_EPOCHS],\n",
        "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUi5RI0QQfNt"
      },
      "source": [
        "# def train_test_model(hparams, logs):\n",
        "#   input_t = tf.keras.Input(shape = (224,224,3))\n",
        "#   VGG19_model = tf.keras.applications.VGG19(input_tensor = input_t,\n",
        "#                                               include_top=False, # do not include ImageNet classifier at the top\n",
        "#                                               weights='imagenet',\n",
        "#                                               )\n",
        "  \n",
        "#   last_conv_layer = VGG19_model.get_layer('block5_pool')\n",
        "  \n",
        "#   conv_model = Model(inputs=VGG19_model.input,\n",
        "#                    outputs=last_conv_layer.output)\n",
        "  \n",
        "#   for layer in conv_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "#   new_model = tf.keras.Sequential()\n",
        "#   new_model.add(conv_model)\n",
        "#   new_model.add(tf.keras.layers.Flatten())\n",
        "#   new_model.add(tf.keras.layers.Dense(512, activation='relu')) \n",
        "#   new_model.add(tf.keras.layers.Dense(2, activation= hparams[HP_ACTIVATION])) \n",
        "  \n",
        "  \n",
        "#   new_model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
        "#                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "#               metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "  \n",
        "#   new_model.fit(\n",
        "#   train_generator,\n",
        "#   steps_per_epoch=steps_train,\n",
        "#   validation_data=val_generator,\n",
        "#   validation_steps = steps_val,\n",
        "#   callbacks = [tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "#                                               write_graph = True,\n",
        "#                                               histogram_freq = 1,\n",
        "#                                               profile_batch = '500,520')],\n",
        "#                                               class_weight = class_weight_dict,\n",
        "#                                               epochs = hparams[HP_EPOCHS]\n",
        "#                                               )\n",
        "\n",
        "#   _, accuracy = new_model.evaluate(val_generator)\n",
        "#   return accuracy\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LF-T8USQrt9"
      },
      "source": [
        "# def run(run_dir, hparams):\n",
        "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
        "#     hp.hparams(hparams)  # record the values used in this trial\n",
        "#     accuracy = train_test_model(hparams, run_dir)\n",
        "#     tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-atQRSpQvxK"
      },
      "source": [
        "# session_num = 0\n",
        "# for dropout_rate in HP_DROPOUT.domain.values:\n",
        "#   for activation in HP_ACTIVATION.domain.values:\n",
        "#     for optimizer in HP_OPTIMIZER.domain.values:\n",
        "#       for epochs in HP_EPOCHS.domain.values:\n",
        "          \n",
        "#           hparams = {\n",
        "#               HP_DROPOUT: dropout_rate,\n",
        "#               HP_ACTIVATION: activation,\n",
        "#               HP_OPTIMIZER: optimizer,\n",
        "#               HP_EPOCHS: epochs,\n",
        "              \n",
        "#           }\n",
        "#           ############ change the folder name here in run ####################\n",
        "#           run_name = \"run-%d\" % session_num\n",
        "#           print('--- Starting trial: %s' % run_name)\n",
        "#           print({h.name: hparams[h] for h in hparams})\n",
        "#           run('./logs/hparam_tuning_VGG/' + run_name, hparams)\n",
        "#           session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwR-B2lJR1cR"
      },
      "source": [
        "# !pip install -U tensorboard_plugin_profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55m_LHgUR1kW"
      },
      "source": [
        "# %tensorboard --logdir ./logs/hparam_tuning_VGG/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}