{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report, precision_score, recall_score\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqiK_AGI086"
      },
      "source": [
        "#Mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6rPivHB2wEh"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount() #you can unmount your drive with this code\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4cgx7VzDH6z"
      },
      "source": [
        "# Project Folder path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al0wP2kSkS3V"
      },
      "source": [
        "project_dir = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/\"\n",
        "%cd {project_dir} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_77wynywgz6"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwewhyRqvQ_r"
      },
      "source": [
        "# Image Labels \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "source": [
        "## labels to be adapted based on desired classification \n",
        "\n",
        "classes = ['crystal', 'no_crystal']\n",
        "# classes = ['amorphous_precipitate', 'clear', 'crystal', 'impurity', 'homogenous_precipitate', 'inhomogenous_precipitate', 'phase_seperation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qor7JU604tSf"
      },
      "source": [
        "# Train / Val +  Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRT_BTAFoPDw"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "\n",
        "#############  TRAIN  ############################################################\n",
        "# Training ImagaDataGenerator with Augmentation.\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255, \n",
        "                                  validation_split=0.3,\n",
        "                                  rotation_range=45, \n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  # shear_range=0.005,\n",
        "                                  # zoom_range=[0.9, 1.4],\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True,\n",
        "                                  brightness_range=(.8,1.2),\n",
        "                                  fill_mode='nearest'\n",
        "                                  )\n",
        "\n",
        "# Create a flow from the directory using  'training' subset.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                project_dir + \"labels/binary_original\", \n",
        "                                # project_dir + \"labels/multi_class\", \n",
        "                                subset='training',\n",
        "                                class_mode='categorical',\n",
        "                                shuffle=True, \n",
        "                                seed=42, \n",
        "                                target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                batch_size=BATCH_SIZE\n",
        "                                )\n",
        "\n",
        "\n",
        "#############  VALIDATION ########################################################\n",
        "# Validation ImageDataGenerator with rescaling.\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255, \n",
        "                                  validation_split=0.3\n",
        "                                  )\n",
        "\n",
        "# Create a flow from the directory for validation data\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "                                  project_dir + \"labels/binary_original\",\n",
        "                                  # project_dir + \"labels/multi_class\", \n",
        "                                  subset='validation',\n",
        "                                  class_mode='categorical',\n",
        "                                  shuffle=True, \n",
        "                                  seed=42, \n",
        "                                  target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                  batch_size=BATCH_SIZE\n",
        "                                  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLQULyAvJC3X"
      },
      "source": [
        "# Get classes from folder names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHAxkHX5JD3k"
      },
      "source": [
        "# class_names = train_generator.labels\n",
        "# print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1oAT80Zy6mn"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-MfMoenJi8s"
      },
      "source": [
        "for image_batch, labels_batch in train_generator:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uoVvxSLJW9m"
      },
      "source": [
        "## Visualize sample data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmEA9c0JYes"
      },
      "source": [
        "# plt.figure(figsize=(10, 10))\n",
        "# for images, labels in train_ds.take(1):\n",
        "#   for i in range(4):\n",
        "#     ax = plt.subplot(2, 2, i + 1)\n",
        "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#     plt.title(class_names[labels[i]])\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dr0at41KcAU"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "# TO BE DONE:  \n",
        "`Dataset.cache()` \n",
        "or\n",
        "`Dataset.prefetch()` \n",
        "(https://www.tensorflow.org/guide/data_performance#prefetching)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOjJSm7DKoZA"
      },
      "source": [
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmpeaN369d-n"
      },
      "source": [
        "## Defining the step size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeUeNhLy9Wek"
      },
      "source": [
        "steps_train = round(train_generator.n / BATCH_SIZE)\n",
        "steps_val = round(val_generator.n / BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1xjo3WeffQ"
      },
      "source": [
        "## Balancing Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOOeEaDKedHj"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(train_generator.classes),\n",
        "                                    y=train_generator.classes)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3OTxtcGhfaX"
      },
      "source": [
        "# class_weight has to be a dictionary format\n",
        "class_weight_dict = { i : class_weights[i] for i in range(0, len(class_weights))}\n",
        "class_weight_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ4RafP3i9YN"
      },
      "source": [
        "# getting number of classes\n",
        "num_classes = len(class_weights)\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7mkhp5RJjcy"
      },
      "source": [
        "# Setting up ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKj5HxqFCDoU"
      },
      "source": [
        "# load a new instance of the ResNet model.\n",
        "ResNet_model = tf.keras.applications.resnet50.ResNet50(input_shape=(224,224,3),\n",
        "                                                      include_top=False,\n",
        "                                                      weights='imagenet'\n",
        "                                                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEKn7vW7CF11"
      },
      "source": [
        "# ResNet_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3tFD-QsqxBa"
      },
      "source": [
        "## Open / Close ResNet Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBx8EpbOdcg1"
      },
      "source": [
        "ResNet_model.trainable = False\n",
        "for layer in ResNet_model.layers:\n",
        "  #  if(('conv5_block3' in layer.name) and ('bn' not in layer.name)):\n",
        "  if(('conv5_block3' in layer.name) and ('bn' not in layer.name)):\n",
        "     layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5e4Sv3guZbO"
      },
      "source": [
        "# #to open all the layers except the batch normalization\n",
        "# ResNet_model.trainable = True\n",
        "# for layer in ResNet_model.layers:\n",
        "#    if 'bn' in layer.name:\n",
        "#      layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXM0LLs4Iq1X"
      },
      "source": [
        "##  see layer status\n",
        "for layer in ResNet_model.layers:\n",
        "    print(layer.name, '->', layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnbjIR9DhPw"
      },
      "source": [
        "# points to last layer\n",
        "last_conv_layer = ResNet_model.get_layer('conv5_block3_out')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mg_vwvJnQM"
      },
      "source": [
        "# Setting up New_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNwLCFExD4wy"
      },
      "source": [
        "num_classes = len(classes)\n",
        "\n",
        "conv_model = Model(inputs=ResNet_model.input,\n",
        "                   outputs=last_conv_layer.output)\n",
        "\n",
        "new_model = Sequential()\n",
        "\n",
        "new_model.add(conv_model)\n",
        "\n",
        "new_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "#new_model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "new_model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# new_model.add(tf.keras.layers.Dense(2, activation=\"relu\")) \n",
        "\n",
        "new_model.add(tf.keras.layers.Dense(2, activation='softmax')) \n",
        "# new_model.add(tf.keras.layers.Dense(7, activation='softmax')) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkk6a0MtTXbu"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD_E6MS46Dxg"
      },
      "source": [
        "optimizer = Adam(lr=1e-4)\n",
        "optimizer.lr.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKFzz72Lqpg"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "Cross entropy loss function for binary classification\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjHlb2comd07"
      },
      "source": [
        "# ## Binary Crossentropy \n",
        "# new_model.compile(optimizer= optimizer,\n",
        "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#               metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t5PywPCa7OF"
      },
      "source": [
        "# # Sparse Categorical\n",
        "# new_model.compile(optimizer= optimizer,\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5E6AwG7lEFn"
      },
      "source": [
        "# Categorical\n",
        "new_model.compile(optimizer= optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMJ4DnuJL55A"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoWU1F46UjZx"
      },
      "source": [
        "## Transfer learning moderl summary.... check if layers are open or not....\n",
        "# conv_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YEXYSl2-QO9"
      },
      "source": [
        "## open orclose transfer leanong model layers\n",
        "# conv_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJxvjEdECs8m"
      },
      "source": [
        "## complete model layers\n",
        "for layer in new_model.layers:\n",
        "    print(layer.name, '->', layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLYH-BXL7Xe"
      },
      "source": [
        "## complete model summary\n",
        "# new_model.build()\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYHcbvaL9H-"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5fWToCqYMErH"
      },
      "source": [
        "%%time\n",
        "\n",
        "epochs = 5\n",
        "history = new_model.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch = steps_train,\n",
        "  validation_data = val_generator,\n",
        "  validation_steps = steps_val,\n",
        "  # callbacks = [tboard_callback],\n",
        "  class_weight = class_weight_dict,\n",
        "  epochs = epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFKdQpXMJT4"
      },
      "source": [
        "## Visualize training results  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jWnopEChMMCn"
      },
      "source": [
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwto09piGhgD"
      },
      "source": [
        "# Save Model\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x6utodzWGeuf"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "new_model.save('saved_model/ResNet') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vei3mjVXHi_1"
      },
      "source": [
        "# ResNet model directory\n",
        "!ls saved_model\n",
        "\n",
        "# Contains an assets folder, saved_model.pb, and variables folder.\n",
        "!ls saved_model/ResNet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtv5VbaVb-3W"
      },
      "source": [
        "## Test / Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dC40sRITBSsQ"
      },
      "source": [
        "folder_path = \"/gdrive/My Drive/Final_Project_CrystalsFirst/Model/labels/test/\"\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if (filename.endswith(\".jpg\") or filename.endswith(\".JPG\")):\n",
        "      img = keras.preprocessing.image.load_img(folder_path+filename,\n",
        "                                               target_size=(IMG_SIZE, IMG_SIZE))\n",
        "      img_array = keras.preprocessing.image.img_to_array(img)/255\n",
        "      img_array = tf.expand_dims(img_array, 0)\n",
        "      pred = new_model.predict(img_array)\n",
        "      predictions[filename] = (classes[np.argmax(pred)],\n",
        "                               (\"confidance of {:.2f}%\".format(100 * np.max(pred))))\n",
        "      continue\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JMwS22-XAp4"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "coerced predictions into a DataFrame. Compared with original lables in JSON file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LeD35VzAOtX-"
      },
      "source": [
        "import pandas as pd\n",
        "# create different df depending on binary / multi calss problem\n",
        "df_json = pd.read_json(project_dir+\"source/image_labels.json\", orient=\"columns\")\n",
        "#df_json = df_json.set_index(\"index\")\n",
        "df_json.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5Sr92ptBu9OK"
      },
      "source": [
        "df_pred = pd.DataFrame.from_dict(predictions, orient=\"index\").reset_index()                    \n",
        "df_pred.columns = [\"image\", \"predictions\",\"confidence\"]\n",
        "df_pred = df_pred.set_index(\"image\")\n",
        "df_pred.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_eXXGIESPYi8"
      },
      "source": [
        "cm_df = df_pred.join(df_json)\n",
        "cm_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dAMngNGZ4i7P"
      },
      "source": [
        "cm_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xFqpShf2XhWZ"
      },
      "source": [
        "cm = confusion_matrix(cm_df.loc[:,\"y_true\"], cm_df.loc[:,\"predictions\"], labels = ['crystal', 'no_crystal'])\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Mu5CjRRmUvNB"
      },
      "source": [
        "import seaborn as sn\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "labels = ['crystal', 'no_crystal']\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "sn.heatmap(cm, annot=True, xticklabels=True, yticklabels=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticklabels(labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZItBxv63JgP"
      },
      "source": [
        "# Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "to30vJKi3HXL"
      },
      "source": [
        "cr = classification_report(cm_df.loc[:,\"y_true\"], cm_df.loc[:,\"predictions\"], labels = ['crystal', 'no_crystal'], digits=2, zero_division='warn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bo4EDL8F4m7I"
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYIF9XpTafUu"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k4IFSqH2Bj5P"
      },
      "source": [
        "#!pip install -U tensorboard_plugin_profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2_H-nlGcX45d"
      },
      "source": [
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e9HMn20Y8AOR"
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "##### only deleting the corresponding folder and not all other folder ###############\n",
        "#!rm -rf ./logs/hparam_tuning_resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Aa5P6DOY8Cn-"
      },
      "source": [
        "# from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LykbBXpm8EwI"
      },
      "source": [
        "# # HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([200, 250, 300]))\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1, 0.2, 0.4]))\n",
        "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'nadam', 'sgd']))\n",
        "# HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['softmax', 'sigmoid']))\n",
        "# HP_LEARNINGRATE = hp.HParam('learningrate', hp.Discrete([0.001, 0.0001, 0.00001]))\n",
        "# HP_EPOCHS = hp.HParam('epochs', hp.Discrete([20, 30, 50]))\n",
        "# HP_BATCHS = hp.HParam('batches', hp.Discrete([2, 5, 8]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wppKDt4Q8G06"
      },
      "source": [
        "# METRIC_ACCURACY = 'categorical_accuracy'\n",
        "\n",
        "# with tf.summary.create_file_writer('./logs/hparam_tuning_resnet').as_default():\n",
        "#   hp.hparams_config(\n",
        "#     hparams=[HP_DROPOUT, HP_OPTIMIZER, HP_ACTIVATION, HP_LEARNINGRATE, HP_EPOCHS, HP_BATCHS],\n",
        "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LFMOuXVt7TJc"
      },
      "source": [
        "#logs = \"./logs/hparam_tuning_resnet\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iAmAO1-uCkgv"
      },
      "source": [
        "# def train_test_model(hparams, logs):\n",
        "# ## ResNet #############################################################################\n",
        "#   conv_model = Model(inputs=ResNet_model.input,\n",
        "#                    outputs=last_conv_layer.output)\n",
        "\n",
        "#   new_model = tf.keras.Sequential()\n",
        "#   new_model.add(conv_model)\n",
        "#   new_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "# # new_model.add(tf.keras.layers.Flatten()) # flatten has similar effect as GAP\n",
        "#   new_model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT])) #dropout after dense layer is usually recommended\n",
        "# # new_model.add(tf.keras.layers.Dense(2, activation=\"relu\")) \n",
        "#   new_model.add(tf.keras.layers.Dense(2, activation= hparams[HP_ACTIVATION])) \n",
        "  \n",
        "  \n",
        "#   new_model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
        "#                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "#                 metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "  \n",
        "\n",
        "#   new_model.fit(\n",
        "#   train_generator,\n",
        "#   steps_per_epoch=steps_train,\n",
        "#   validation_data=val_generator,\n",
        "#   validation_steps = steps_val,\n",
        "#   callbacks = [tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "#                                                  write_graph = True,\n",
        "#                                                  histogram_freq = 1,\n",
        "#                                                  profile_batch = '500,520')],\n",
        "#   class_weight = class_weight_dict,\n",
        "#   epochs = hparams[HP_EPOCHS]\n",
        "\n",
        "# )\n",
        "\n",
        "#   _, accuracy = new_model.evaluate(val_generator)\n",
        "#   return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2SjWxr2sHWvc"
      },
      "source": [
        "# def run(run_dir, hparams):\n",
        "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
        "#     hp.hparams(hparams)  # record the values used in this trial\n",
        "#     accuracy = train_test_model(hparams, run_dir)\n",
        "#     tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XfDqBektHgvY"
      },
      "source": [
        "# session_num = 0\n",
        "# for dropout_rate in HP_DROPOUT.domain.values:\n",
        "#   for activation in HP_ACTIVATION.domain.values:\n",
        "#     for optimizer in HP_OPTIMIZER.domain.values:\n",
        "#       for epochs in HP_EPOCHS.domain.values:\n",
        "          \n",
        "#           hparams = {\n",
        "#               HP_DROPOUT: dropout_rate,\n",
        "#               HP_ACTIVATION: activation,\n",
        "#               HP_OPTIMIZER: optimizer,\n",
        "#               HP_EPOCHS: epochs,\n",
        "              \n",
        "#           }\n",
        "\n",
        "#           ############ change the folder name here in run #################### WE CREATE THE LOGS NAME HERE, DONT CREATE ANOTHER ONE\n",
        "#           run_name = \"run-%d\" % session_num\n",
        "#           print('--- Starting trial: %s' % run_name)\n",
        "#           print({h.name: hparams[h] for h in hparams})\n",
        "#           run('./logs/hparam_tuning_resnet/' + run_name, hparams)\n",
        "#           session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pneXvJcxMRc"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nFBCDv9ckYFq"
      },
      "source": [
        "# os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-kPjr1jcBsBl"
      },
      "source": [
        "# ! kill 25290"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z7VOXX9BHjun"
      },
      "source": [
        "# %tensorboard --logdir ./logs/hparam_tuning_resnet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8U2wCxnzuaY"
      },
      "source": [
        "sgd and adam using softmax with .2 or .4 dropout, 20 or 30 epochs gives the highes accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-oJPzWXEiPeB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}